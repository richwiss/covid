{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches':None}\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-time directory setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loc = '.'\n",
    "population_loc = f'{base_loc}/resources'\n",
    "\n",
    "# jhu_loc is the root directory of the JHU data repository\n",
    "jhu_loc = f'{base_loc}/COVID-19'\n",
    "csse_loc = f'{jhu_loc}/csse_covid_19_data/csse_covid_19_daily_reports'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load population and region data\n",
    "\n",
    "Note: Regions only supported for Pennsylvania in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_population_data():\n",
    "    \"\"\" load population and region data for counties in PA \"\"\"\n",
    "    df = pd.read_csv(f'{population_loc}/county-populations.csv')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load JHU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\" read all the CSV files into a single data frame \"\"\"\n",
    "    csv_files = [fname for fname in os.listdir(csse_loc) if fname.endswith('.csv')]\n",
    "    data = []\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(f'{csse_loc}/{csv_file}', dtype={\"FIPS\": str})\n",
    "        # At some point JHU renamed some columns\n",
    "        df = df.rename(columns={'Province/State': 'Province_State', \n",
    "                                'Last Update': 'Last_Update',\n",
    "                                'Country/Region': 'Country_Region',\n",
    "                                'Latitude': 'Lat',\n",
    "                                'Longitude': 'Long_'})\n",
    "\n",
    "        data.append(df)\n",
    "\n",
    "    df = pd.concat(data, ignore_index=True)\n",
    "\n",
    "    # Remove unneeded columns\n",
    "    df = df.drop(columns=['Lat', 'Long_', 'Combined_Key', 'FIPS'])\n",
    "    \n",
    "    # In later data, \"Active\" = \"Confirmed\" - \"Deaths\". If \"Active\" == 0, compute it\n",
    "    \n",
    "\n",
    "    # Standardize all dates to noon\n",
    "    df.Last_Update = pd.to_datetime(df.Last_Update)\n",
    "    df.Last_Update = df.Last_Update.dt.strftime('%m/%d/%Y')\n",
    "    df.Last_Update = pd.to_datetime(df.Last_Update)\n",
    "\n",
    "    # Fix \"active\" column when it is set to 0 prior to it being reported\n",
    "    def active_fn(row):\n",
    "        if row.Active == 0:\n",
    "            return row.Confirmed - row.Recovered - row.Deaths\n",
    "        else:\n",
    "            return row.Active\n",
    "\n",
    "    df = df.assign(Active=df.apply(active_fn, axis=1)) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locality Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge and filter all data for just one state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_state(df, state, popdf):\n",
    "    \"\"\" merge individual counties in a state into a single row \"\"\"\n",
    "    statepop_dict = state_populations(popdf)\n",
    "\n",
    "    merged = pd.DataFrame()\n",
    "    merged['Last_Update'] = df[df.Province_State==state].groupby(df.Last_Update)['Last_Update'].unique()    \n",
    "    merged['Admin2'] = 'All'\n",
    "    merged['Province_State'] = state\n",
    "    merged['Country_Region'] = df.Country_Region.unique()[0]\n",
    "\n",
    "    merged['Deaths'] = df[df.Province_State==state].groupby(df.Last_Update)['Deaths'].sum()\n",
    "    merged['Confirmed'] = df[df.Province_State==state].groupby(df.Last_Update)['Confirmed'].sum()\n",
    "    merged['Recovered'] = df[df.Province_State==state].groupby(df.Last_Update)['Recovered'].sum()\n",
    "    merged['Active'] = df[df.Province_State==state].groupby(df.Last_Update)['Active'].sum()\n",
    "    merged['Population'] = statepop_dict[state]\n",
    "\n",
    "    merged['Last_Update'] = merged.index\n",
    "    merged.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_data(state, df):\n",
    "    state_matches = df[(df.Province_State==state)]\n",
    "    state_matches.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return pd.DataFrame(state_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge for just one region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_region(df, region, popdf):\n",
    "    \"\"\" for PA, merge the data into regions \"\"\"\n",
    "    regionpop_dict = region_populations(popdf)\n",
    "    \n",
    "    merged = pd.DataFrame()\n",
    "    merged['Last_Update'] = df[df.Region==region].groupby(df.Last_Update)['Last_Update'].unique()    \n",
    "    merged['Admin2'] = region\n",
    "    merged['Province_State'] = df.Province_State.unique()[0]\n",
    "    merged['Country_Region'] = df.Country_Region.unique()[0]\n",
    "\n",
    "    merged['Deaths'] = df[df.Region==region].groupby(df.Last_Update)['Deaths'].sum()\n",
    "    merged['Confirmed'] = df[df.Region==region].groupby(df.Last_Update)['Confirmed'].sum()\n",
    "    merged['Recovered'] = df[df.Region==region].groupby(df.Last_Update)['Recovered'].sum()\n",
    "    merged['Active'] = df[df.Region==region].groupby(df.Last_Update)['Active'].sum()\n",
    "\n",
    "    merged['Population'] = regionpop_dict[region]\n",
    "    \n",
    "    merged['Last_Update'] = merged.index\n",
    "    merged.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter all data for just one county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_county_data(state, county, df):\n",
    "    county_matches = df[(df.Province_State==state) & (df.Admin2==county)]\n",
    "    county_matches.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return pd.DataFrame(county_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotate the dataframe with region information, if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_regions(df, popdf):\n",
    "    \"\"\" For counties in Pennsylvania, annotate the dataframe with the region \"\"\"\n",
    "    \n",
    "    def annotator(row):\n",
    "        poprow = popdf[(popdf.State==row.Province_State)&(popdf.County==row.Admin2)]\n",
    "        if len(poprow) == 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return poprow.Region.values[0]\n",
    "\n",
    "    df['Region'] = df.apply(annotator, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotate the dataframe with populations, if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_populations(df, popdf):\n",
    "    \"\"\" Annotate the dataframe with populations, if available \"\"\"\n",
    "        \n",
    "    def annotator(row):\n",
    "        poprow = popdf[(popdf.State==row.Province_State)&(popdf.County==row.Admin2)]\n",
    "        if len(poprow) == 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return poprow.Population.values[0]\n",
    "\n",
    "    df['Population'] = df.apply(annotator, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_populations(popdf):\n",
    "    return dict(popdf.groupby(popdf.State)['Population'].sum().items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_populations(popdf):\n",
    "    \"\"\" for PA, calculate the population of each region \"\"\"   \n",
    "    return dict(popdf.groupby(popdf.Region)['Population'].sum().items())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the appropriate locality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_locality(all_df, popdf, query_type, query_state=None, query_region=None, query_county=None):\n",
    "    if query_type == 'State':\n",
    "        label = f'{query_state} State'\n",
    "        df = get_state_data(query_state, all_df)\n",
    "        df = merge_state(df, query_state, popdf)\n",
    "    elif query_type == 'Region':\n",
    "        label = f'{query_region} Region, {query_state}'\n",
    "        df = get_state_data(query_state, all_df)\n",
    "        if 'Region' in df.columns:\n",
    "            df['Admin2'] = df['Region']\n",
    "        else:\n",
    "            annotate_regions(df, popdf)\n",
    "        df = merge_region(df, query_region, popdf)\n",
    "    elif query_type == 'County':\n",
    "        label = f'{query_county} County, {query_state}'\n",
    "        df=get_county_data(query_state, query_county, all_df)\n",
    "        annotate_populations(df, popdf)\n",
    "    \n",
    "    return df, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute daily and average new cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_cases(df):\n",
    "    \"\"\" given a DataFrame with a .Confirmed field, add a .New_Cases field that\n",
    "    has new cases per day. \"\"\"\n",
    "    df['New_Cases'] = df.Confirmed.subtract(df.Confirmed.shift(1), fill_value=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_new_cases(df, days, centered=False):\n",
    "    \"\"\" this computes day the trailing average in the final day \"\"\"\n",
    "    \"\"\" compute the moving average over {days} days and add as day_avg_{days} to the df \"\"\"\n",
    "    field = f'day_avg_{days}'\n",
    "    df[field] = df.New_Cases.rolling(window=14, min_periods=1, center=centered).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_avg(dates):\n",
    "  refdate = datetime.datetime(2019, 1, 1)\n",
    "  return refdate + sum([date - refdate for date in dates], datetime.timedelta()) / len(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for graphing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily new cases and 7-day moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_case_plot(df, label, days=7, centered=False, output=None):\n",
    "\n",
    "    if centered:\n",
    "        date_field = f'Centered_Date_{days}'\n",
    "    else:\n",
    "        date_field='Last_Update'\n",
    "    average_new_cases(df, days, centered=centered)\n",
    "\n",
    "        \n",
    "    g = sns.lineplot(df['Last_Update'], df['New_Cases'], label=\"Daily new cases\")\n",
    "    sns.lineplot(df[date_field], df[f'day_avg_{days}'], ax=g, label=f\"{days} day moving average\")\n",
    "    g.set(xlabel=\"\\nDate\", ylabel=\"New Cases\", title=f\"New Cases Per Day\\n{label}\")\n",
    "    leg = g.legend(loc='upper left', frameon=False)\n",
    "    plt.xticks(rotation=90)\n",
    "    if output == None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        output = output.replace('.png', '_new_cases.png')\n",
    "        plt.savefig(output, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yellow target: 50 new cases over 14 days per 100K people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newcase_sum(df, days, perpop=1):\n",
    "    \"\"\" \n",
    "    compute the sum of {days} days and {days}_sum to the df \n",
    "    if perpop is not 1, calculate the same weighted by the population pop\n",
    "    \"\"\"\n",
    "    field = f'sum_{days}'\n",
    "    df[field] = df.New_Cases.rolling(window=days, min_periods=1).sum()\n",
    "    df[field] *= perpop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yellow_target(df, label, output=None):\n",
    "    population = set(df.Population).pop()\n",
    "    newcase_sum(df, 14, perpop=100000/population)\n",
    "    target = 50\n",
    "    \n",
    "    g = sns.lineplot(df['Last_Update'], df['sum_14'], label=\"14 day caseload per 100K\")\n",
    "    sns.lineplot(df['Last_Update'], [target]*len(df), label=\"Yellow Target\", ax=g)\n",
    "    g.set(xlabel=\"\\nDate\", ylabel=\"14 days cases per 100K\", title=f\"Progress towards yellow target\\n{label}\")\n",
    "    leg = g.legend(loc='lower right', frameon=False)\n",
    "    plt.xticks(rotation=90)\n",
    "    if output == None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        output = output.replace('.png', '_yellow_target.png')\n",
    "        plt.savefig(output, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days trending downward in 14 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_xticks(labels, num=5):\n",
    "    \"\"\"\n",
    "    For some reason I can't limit the number of xticks so here I'm\n",
    "    just doing it myself by erasing the text of the xticks I don't want\n",
    "    \"\"\"\n",
    "        \n",
    "    target_ticks = set([0, len(labels)-1])\n",
    "    for i in range(1, num-1):\n",
    "        pos= int(round(len(labels)/(num-1)*i,0))\n",
    "        target_ticks.add(pos)\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        if i not in target_ticks:\n",
    "            labels[i].set_text(\"\")\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(period):\n",
    "    if len(period) == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        m, b = np.polyfit(np.arange(len(period)), period, 1)\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend(df, days):\n",
    "    \"\"\" \n",
    "    compute the trendline for the past {days} days as slope_{days} and\n",
    "    the number of days within those {days} that the trend is worsening \n",
    "    (positive) or improving (negative) as {days}_trend\n",
    "    \"\"\"\n",
    "    slopes = []\n",
    "    trends = []\n",
    "\n",
    "    # Get the slope of the trend line for the past {days} days.\n",
    "    sfield=f'slope_{days}'\n",
    "    df[sfield] = df.New_Cases.rolling(window=days, min_periods=1).apply(fit)\n",
    "\n",
    "    # Get the number of times the slope was positive in last {days} days.\n",
    "    field = f'trend_{days}'\n",
    "    df[field] = df[sfield].rolling(window=14, min_periods=14).apply(lambda x: (x>0).sum())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trending(df, label, days=14, output=None):\n",
    "    df = trend(df, 14)\n",
    "\n",
    "    tfield = f'trend_{days}'\n",
    "    sfield = f'slope_{days}'\n",
    "    \n",
    "    formatted_dates = df['Last_Update'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    g=sns.barplot(formatted_dates, df[tfield], label=\"increasing trends\", color='red')\n",
    "    sns.barplot(formatted_dates, df[tfield]-14, label=\"decreasing trends\", color='green')\n",
    "    t = g.twinx()\n",
    "    \n",
    "    sns.lineplot(np.arange(len(df)), df[sfield], color=\"black\", label=\"14-day slope\", ax=t)\n",
    "    #slopes = np.where(df['trend_14'].isnull(), 0, df['slope_14'])\n",
    "    #sns.lineplot(np.arange(len(df)), slopes, color=\"black\", label=\"14-day slope\", ax=t)\n",
    "\n",
    "    labels = limit_xticks(g.get_xticklabels())\n",
    "    g.set_xticklabels(labels,rotation=90)\n",
    "\n",
    "    g.set_ylim(-14,14)\n",
    "    title=f\"Number of days in the past two weeks with a positive or negative trend\\n{label}\"\n",
    "    g.set(xlabel=\"\\nDate\", ylabel=\"Number of days\", title=title)\n",
    "    t.set(ylabel=\"slope of 14-day trend\")\n",
    "    slope_lim = max(abs(df[df[sfield].notna()][sfield]))*1.1\n",
    "    t.set_ylim(-slope_lim,slope_lim)\n",
    "    leg = t.legend(loc='lower left', frameon=False)\n",
    "\n",
    "    if output is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        output = output.replace('.png', '_trend.png')\n",
    "        plt.savefig(output, bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issues\n",
    "\n",
    "* States allocate cases to \"Unassigned\" if county is unknown\n",
    "* \"Out of CO\", \"Out of GA\", \"Out of MI\", \"Out of OK\", \"Out of TN\" is listed as a county\n",
    "* Dukes, MA and Nantucket, MA -> \"Dukes and Nantucket\"\n",
    "* Federal Correctional Institution (FCI), MI; Michigan Department of Corrections (MDOC), MI\n",
    "* Kansas City, MO reported as a standalone county when it actually appears in multiple counties\n",
    "* New York City, NY is reported but counties are Richmond, Queens, New York, Kings and Bronx\n",
    "* Counties in Utah don't align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read JHU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read county population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "popdf = load_population_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output all graphs for specified state, region or county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(all_df, popdf, query_type, query_state=None, query_region=None, query_county=None, output=None, \n",
    "                output_directory=None):\n",
    "    assert query_type in ['State', 'County', 'Region']\n",
    "    assert output in ['inline', 'png']\n",
    "\n",
    "    df, label = select_locality(all_df, popdf, query_type, query_state, query_region, query_county)\n",
    "    df = df.sort_values(by='Last_Update', ignore_index=True)\n",
    "    if output == 'png':\n",
    "        output = label.replace(' ','_') + '.png'\n",
    "        output = output.replace(',','')\n",
    "        if output_directory==None:\n",
    "            output_directory='png'\n",
    "        output = f\"{output_directory}/{output}\"\n",
    "    else:\n",
    "        output = None\n",
    "    \n",
    "    new_cases(df) # add a new_cases column to the dataframe\n",
    "    new_case_plot(df, label, days=14, centered=False, output=output)    \n",
    "    plt.close()\n",
    "    yellow_target(df, label, output=output)\n",
    "    plt.close()\n",
    "    trending(df, label, output=output)\n",
    "    plt.close()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate state graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pennsylvania:York                : 100%|██████████| 67/67 [01:40<00:00,  1.50s/it]\n",
      "Pennsylvania:South West          : 100%|██████████| 6/6 [00:09<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All states completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "states = ['Pennsylvania', 'Georgia', 'New York', 'Florida', 'New Jersey']\n",
    "#states = ['Pennsylvania']\n",
    "#states = ['Georgia', 'New York', 'Florida', 'New Jersey']\n",
    "#states = ['Pennsylvania']\n",
    "statedir = 'states'\n",
    "for state in states:\n",
    "    print(state)\n",
    "    outdir = f'{statedir}/{state}'.replace(' ','_')\n",
    "    counties = set(popdf[popdf.State==state].County)\n",
    "\n",
    "    if state == 'New York': # remove NYC counties; JHU conflates into a single county\n",
    "        counties -= set(['Bronx', 'New York', 'Kings', 'Queens', 'Richmond', 'New York City'])\n",
    "\n",
    "    state_df = get_state_data(state, all_df)\n",
    "    #state_df = all_df\n",
    "\n",
    "    pbar = tqdm(sorted(counties))\n",
    "    for county in pbar:\n",
    "        pbar.set_description(f\"{state}:{county:20}\")\n",
    "        run_pipeline(state_df, popdf, query_type=\"County\", query_state=state, query_county=county, output=\"png\",\n",
    "                    output_directory=outdir)\n",
    "        \n",
    "    # Annotate Regions\n",
    "    region_map = defaultdict(lambda: np.nan)\n",
    "    for d in popdf.to_dict('records'):\n",
    "        region_map[d['State'], d['County']] = d['Region']\n",
    "    state_df['Region'] = state_df[['Province_State', 'Admin2']].apply(lambda x: region_map[x[0], x[1]], axis=1)\n",
    "    \n",
    "    regions = set(popdf.Region[(popdf.Region.notnull()) & (popdf.State==state)])\n",
    "\n",
    "    pbar = tqdm(sorted(regions))\n",
    "    for region in pbar:\n",
    "        pbar.set_description(f\"{state}:{region:20}\")\n",
    "        df = run_pipeline(state_df, popdf, query_type=\"Region\", query_state=state, query_region=region, output=\"png\",\n",
    "                     output_directory=outdir)\n",
    "        \n",
    "    run_pipeline(state_df, popdf, query_type=\"State\", query_state=state, output='png',\n",
    "                 output_directory=outdir)\n",
    "\n",
    "print(f\"All states completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  1.18681319,  1.65054945,\n",
       "        1.44395604,  2.20659341,  1.96043956,  1.73406593,  1.74725275,\n",
       "        2.09230769,  1.92967033,  1.67252747,  1.34945055,  0.72747253,\n",
       "        0.20879121, -0.1010989 ,  0.14725275, -0.00659341, -0.72527473,\n",
       "        0.07472527, -0.4       , -1.12307692, -1.14065934, -0.77142857,\n",
       "       -0.67692308, -0.68351648, -0.68791209, -1.14505495, -1.10769231,\n",
       "       -0.99340659, -0.38241758, -0.57582418, -0.8       , -0.4       ,\n",
       "       -0.1032967 , -0.26813187, -0.09450549,  0.61318681,  0.52747253,\n",
       "        0.33846154, -0.01098901, -0.13406593, -0.17142857])"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(df['trend_14'].isnull(), 0, df['slope_14'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-off graphs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Setup variables for this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_off=False\n",
    "if one_off:\n",
    "    query_type='Region'\n",
    "    query_state='New York'\n",
    "    query_region='New York City'\n",
    "    query_county=None\n",
    "    output='png'\n",
    "    output_dir='png'\n",
    "    df = run_pipeline(all_df, popdf, query_type=\"Region\", query_state=query_state, query_county=query_county, \n",
    "                      query_region=query_region, output=\"png\", output_directory=outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('nlp': virtualenv)",
   "language": "python",
   "name": "python37764bitnlpvirtualenv16bd9fbbc17243058c9cd2c35a0e7820"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
