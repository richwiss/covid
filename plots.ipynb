{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches':None}\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-time directory setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loc = '.'\n",
    "population_loc = f'{base_loc}/resources'\n",
    "\n",
    "# jhu_loc is the root directory of the JHU data repository\n",
    "jhu_loc = f'{base_loc}/COVID-19'\n",
    "csse_loc = f'{jhu_loc}/csse_covid_19_data/csse_covid_19_daily_reports'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load population and region data\n",
    "\n",
    "Note: Regions only supported for Pennsylvania in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_population_data():\n",
    "    \"\"\" load population and region data for counties in PA \"\"\"\n",
    "    df = pd.read_csv(f'{population_loc}/county-populations.csv')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load JHU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\" read all the CSV files into a single data frame \"\"\"\n",
    "    csv_files = [fname for fname in os.listdir(csse_loc) if fname.endswith('.csv')]\n",
    "    data = []\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(f'{csse_loc}/{csv_file}', dtype={\"FIPS\": str})\n",
    "        # At some point JHU renamed some columns\n",
    "        df = df.rename(columns={'Province/State': 'Province_State', \n",
    "                                'Last Update': 'Last_Update',\n",
    "                                'Country/Region': 'Country_Region',\n",
    "                                'Latitude': 'Lat',\n",
    "                                'Longitude': 'Long_'})\n",
    "\n",
    "        data.append(df)\n",
    "\n",
    "    df = pd.concat(data, ignore_index=True)\n",
    "\n",
    "    # Remove unneeded columns\n",
    "    df = df.drop(columns=['Lat', 'Long_', 'Combined_Key', 'FIPS'])\n",
    "    \n",
    "    # In later data, \"Active\" = \"Confirmed\" - \"Deaths\". If \"Active\" == 0, compute it\n",
    "    \n",
    "\n",
    "    # Standardize all dates to noon\n",
    "    df.Last_Update = pd.to_datetime(df.Last_Update)\n",
    "    df.Last_Update = df.Last_Update.dt.strftime('%m/%d/%Y')\n",
    "    df.Last_Update = pd.to_datetime(df.Last_Update)\n",
    "\n",
    "    # Fix \"active\" column when it is set to 0 prior to it being reported\n",
    "    def active_fn(row):\n",
    "        if row.Active == 0:\n",
    "            return row.Confirmed - row.Recovered - row.Deaths\n",
    "        else:\n",
    "            return row.Active\n",
    "\n",
    "    df = df.assign(Active=df.apply(active_fn, axis=1)) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locality Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge and filter all data for just one state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_state(df, state, popdf):\n",
    "    \"\"\" merge individual counties in a state into a single row \"\"\"\n",
    "    statepop_dict = state_populations(popdf)\n",
    "\n",
    "    merged = pd.DataFrame()\n",
    "    merged['Last_Update'] = df[df.Province_State==state].groupby(df.Last_Update)['Last_Update'].unique()    \n",
    "    merged['Admin2'] = 'All'\n",
    "    merged['Province_State'] = state\n",
    "    merged['Country_Region'] = df.Country_Region.unique()[0]\n",
    "\n",
    "    merged['Deaths'] = df[df.Province_State==state].groupby(df.Last_Update)['Deaths'].sum()\n",
    "    merged['Confirmed'] = df[df.Province_State==state].groupby(df.Last_Update)['Confirmed'].sum()\n",
    "    merged['Recovered'] = df[df.Province_State==state].groupby(df.Last_Update)['Recovered'].sum()\n",
    "    merged['Active'] = df[df.Province_State==state].groupby(df.Last_Update)['Active'].sum()\n",
    "    merged['Population'] = statepop_dict[state]\n",
    "\n",
    "    merged['Last_Update'] = merged.index\n",
    "    merged.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_data(state, df):\n",
    "    state_matches = df[(df.Province_State==state)]\n",
    "    state_matches.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return pd.DataFrame(state_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge for just one region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_region(df, region, popdf):\n",
    "    \"\"\" for PA, merge the data into regions \"\"\"\n",
    "    regionpop_dict = region_populations(popdf)\n",
    "    \n",
    "    merged = pd.DataFrame()\n",
    "    merged['Last_Update'] = df[df.Region==region].groupby(df.Last_Update)['Last_Update'].unique()    \n",
    "    merged['Admin2'] = region\n",
    "    merged['Province_State'] = df.Province_State.unique()[0]\n",
    "    merged['Country_Region'] = df.Country_Region.unique()[0]\n",
    "\n",
    "    merged['Deaths'] = df[df.Region==region].groupby(df.Last_Update)['Deaths'].sum()\n",
    "    merged['Confirmed'] = df[df.Region==region].groupby(df.Last_Update)['Confirmed'].sum()\n",
    "    merged['Recovered'] = df[df.Region==region].groupby(df.Last_Update)['Recovered'].sum()\n",
    "    merged['Active'] = df[df.Region==region].groupby(df.Last_Update)['Active'].sum()\n",
    "\n",
    "    merged['Population'] = regionpop_dict[region]\n",
    "    \n",
    "    merged['Last_Update'] = merged.index\n",
    "    merged.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter all data for just one county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_county_data(state, county, df):\n",
    "    county_matches = df[(df.Province_State==state) & (df.Admin2==county)]\n",
    "    county_matches.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return pd.DataFrame(county_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotate the dataframe with region information, if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_regions(df, popdf):\n",
    "    \"\"\" For counties in Pennsylvania, annotate the dataframe with the region \"\"\"\n",
    "        \n",
    "    def annotator(row):\n",
    "        poprow = popdf[(popdf.State==row.Province_State)&(popdf.County==row.Admin2)]\n",
    "        if len(poprow) == 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return poprow.Region.values[0]\n",
    "\n",
    "    df['Region'] = df.apply(annotator, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotate the dataframe with populations, if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_populations(df, popdf):\n",
    "    \"\"\" Annotate the dataframe with populations, if available \"\"\"\n",
    "        \n",
    "    def annotator(row):\n",
    "        poprow = popdf[(popdf.State==row.Province_State)&(popdf.County==row.Admin2)]\n",
    "        if len(poprow) == 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return poprow.Population.values[0]\n",
    "\n",
    "    df['Population'] = df.apply(annotator, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_populations(popdf):\n",
    "    return dict(popdf.groupby(popdf.State)['Population'].sum().items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_populations(popdf):\n",
    "    \"\"\" for PA, calculate the population of each region \"\"\"   \n",
    "    return dict(popdf.groupby(popdf.Region)['Population'].sum().items())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the appropriate locality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_locality(all_df, popdf, query_type, query_state=None, query_region=None, query_county=None):\n",
    "    if query_type == 'State':\n",
    "        label = f'{query_state} State'\n",
    "        df = get_state_data(query_state, all_df)\n",
    "        df = merge_state(df, query_state, popdf)\n",
    "    elif query_type == 'Region':\n",
    "        label = f'{query_region} Region, {query_state}'\n",
    "        df = get_state_data(query_state, all_df)\n",
    "        annotate_regions(df, popdf)\n",
    "        df = merge_region(df, query_region, popdf)\n",
    "    elif query_type == 'County':\n",
    "        label = f'{query_county} County, {query_state}'\n",
    "        df=get_county_data(query_state, query_county, all_df)\n",
    "        annotate_populations(df, popdf)\n",
    "    \n",
    "    return df, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute daily and average new cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_cases(df):\n",
    "    \"\"\" given a DataFrame with a .Confirmed field, add a .New_Cases field that\n",
    "    has new cases per day. \"\"\"\n",
    "    confirmed = df.Confirmed\n",
    "    new_cases = [confirmed[i]-confirmed[i-1] for i in range(1, len(confirmed))]\n",
    "    new_cases = [0] + new_cases\n",
    "    df['New_Cases'] = new_cases\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_new_cases(df, days):\n",
    "    \"\"\" this computes day the trailing average in the final day \"\"\"\n",
    "    \"\"\" compute the moving average over {days} days and add as day_avg_{days} to the df \"\"\"\n",
    "    \n",
    "    avg = []\n",
    "    # This is not very pandas-like\n",
    "    for i, row in df.iterrows():\n",
    "        avg.append(np.average(df.New_Cases.iloc[max(0,i-days+1):(i+1)]))\n",
    "    field = f'day_avg_{days}'\n",
    "    df[field] = avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_avg(dates):\n",
    "  refdate = datetime.datetime(2019, 1, 1)\n",
    "  return refdate + sum([date - refdate for date in dates], datetime.timedelta()) / len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_new_cases_centered(df, days):\n",
    "    \"\"\" this computes day the trailing average in the final day \"\"\"\n",
    "    \"\"\" compute the moving average over {days} days and add as day_avg_{days} to the df \"\"\"\n",
    "    average_new_cases(df, days)\n",
    "    \n",
    "    avg_date = []\n",
    "    #adjust dates\n",
    "    for i, row in df.iterrows():\n",
    "        avg_date.append(date_avg(df.Last_Update.iloc[max(0,i-days+1):(i+1)]))\n",
    "    field = f'Centered_Date_{days}'\n",
    "    df[field] = avg_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for graphing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily new cases and 7-day moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_case_plot(df, label, days=7, centered=False, output=None):\n",
    "\n",
    "    if centered:\n",
    "        average_new_cases_centered(df, days)\n",
    "        date_field = f'Centered_Date_{days}'\n",
    "    else:\n",
    "        average_new_cases(df, days)\n",
    "        date_field='Last_Update'\n",
    "    \n",
    "    g = sns.lineplot(df['Last_Update'], df['New_Cases'], label=\"Daily new cases\")\n",
    "    sns.lineplot(df[date_field], df[f'day_avg_{days}'], ax=g, label=f\"{days} day moving average\")\n",
    "    g.set(xlabel=\"\\nDate\", ylabel=\"New Cases\", title=f\"New Cases Per Day\\n{label}\")\n",
    "    leg = g.legend(loc='upper left', frameon=False)\n",
    "    plt.xticks(rotation=90)\n",
    "    if output == None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        output = output.replace('.png', '_new_cases.png')\n",
    "        plt.savefig(output, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yellow target: 50 new cases over 14 days per 100K people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newcase_sum(df, days, perpop=1):\n",
    "    \"\"\" \n",
    "    compute the sum of {days} days and {days}_sum to the df \n",
    "    if perpop is not 1, calculate the same weighted by the population pop\n",
    "    \"\"\"\n",
    "    \n",
    "    sums = []\n",
    "    # This is not very pandas-like\n",
    "    for i, row in df.iterrows():\n",
    "        value = sum(df.New_Cases.iloc[max(0,i-days+1):(i+1)]) * perpop\n",
    "        sums.append(value)\n",
    "    field = f'sum_{days}'\n",
    "    df[field] =sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yellow_target(df, label, output=None):\n",
    "    population = set(df.Population).pop()\n",
    "    newcase_sum(df, 14, perpop=100000/population)\n",
    "    target = 50\n",
    "    \n",
    "    g = sns.lineplot(df['Last_Update'], df['sum_14'], label=\"14 day caseload per 100K\")\n",
    "    sns.lineplot(df['Last_Update'], [target]*len(df), label=\"Yellow Target\", ax=g)\n",
    "    g.set(xlabel=\"\\nDate\", ylabel=\"14 days cases per 100K\", title=f\"Progress towards yellow target\\n{label}\")\n",
    "    leg = g.legend(loc='lower right', frameon=False)\n",
    "    plt.xticks(rotation=90)\n",
    "    if output == None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        output = output.replace('.png', '_yellow_target.png')\n",
    "        plt.savefig(output, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days trending downward in 14 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_xticks(labels, num=5):\n",
    "    \"\"\"\n",
    "    for some reason i can't limit the number of xticks so here i'm\n",
    "    just doing it myself by erasing the text of the xticks i don't want\n",
    "    \"\"\"\n",
    "        \n",
    "    target_ticks = set([0, len(labels)-1])\n",
    "    for i in range(1, num-1):\n",
    "        pos= int(round(len(labels)/(num-1)*i,0))\n",
    "        target_ticks.add(pos)\n",
    "\n",
    "    for i, lab in enumerate(labels):\n",
    "        if i not in target_ticks:\n",
    "            labels[i].set_text(\"\")\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend(df, days):\n",
    "    \"\"\" \n",
    "    compute the trendline for the past {days} days as slope_{days} and\n",
    "    the number of days within those {days} that the trend is worsening \n",
    "    (positive) or improving (negative) as {days}_trend\n",
    "    \"\"\"\n",
    "    slopes = []\n",
    "    trends = []\n",
    "    # This is not very pandas-like\n",
    "    for i, row in df.iterrows():\n",
    "        if i < 1:\n",
    "            slopes.append(np.NaN)\n",
    "        else:\n",
    "            data = df.New_Cases.iloc[max(0, i-days+1):i+1]\n",
    "            m, b = np.polyfit(np.arange(len(data)), data, 1)\n",
    "            slopes.append(m)\n",
    "            \n",
    "    field=f'slope_{days}'\n",
    "    df[field] = slopes\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        if i < days:\n",
    "            trends.append(np.NaN)\n",
    "        else:\n",
    "            data = df[field].iloc[i-days+1:i+1]\n",
    "            trends.append((data > 0).sum())\n",
    "    df[f'trend_{days}'] = trends\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trending(df, label, days=14, output=None):\n",
    "    df = trend(df, 14)\n",
    "\n",
    "    formatted_dates = df['Last_Update'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    g=sns.barplot(formatted_dates, df['trend_14'], label=\"increasing trends\", color='red')\n",
    "    sns.barplot(formatted_dates, df['trend_14']-14, label=\"decreasing trends\", color='green')\n",
    "    t = g.twinx()\n",
    "    sns.lineplot(np.arange(len(df)), df['slope_14'], color=\"black\", label=\"14-day slope\", ax=t)\n",
    "\n",
    "    labels = limit_xticks(g.get_xticklabels())\n",
    "    g.set_xticklabels(labels,rotation=90)\n",
    "\n",
    "    g.set_ylim(-14,14)\n",
    "    title=f\"Number of days in the past two weeks with a positive or negative trend\\n{label}\"\n",
    "    g.set(xlabel=\"\\nDate\", ylabel=\"Number of days\", title=title)\n",
    "    t.set(ylabel=\"slope of 14-day trend\")\n",
    "    slope_lim = max(abs(df[df['slope_14'].notna()].slope_14))*1.1\n",
    "    t.set_ylim(-slope_lim,slope_lim)\n",
    "    leg = t.legend(loc='lower left', frameon=False)\n",
    "\n",
    "    if output is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        output = output.replace('.png', '_trend.png')\n",
    "        plt.savefig(output, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issues\n",
    "\n",
    "* States allocate cases to \"Unassigned\" if county is unknown\n",
    "* \"Out of CO\", \"Out of GA\", \"Out of MI\", \"Out of OK\", \"Out of TN\" is listed as a county\n",
    "* Dukes, MA and Nantucket, MA -> \"Dukes and Nantucket\"\n",
    "* Federal Correctional Institution (FCI), MI; Michigan Department of Corrections (MDOC), MI\n",
    "* Kansas City, MO reported as a standalone county when it actually appears in multiple counties\n",
    "* New York City, NY is reported but counties are Richmond, Queens, New York, Kings and Bronx\n",
    "* Counties in Utah don't align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read JHU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read county population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "popdf = load_population_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output all graphs for specified state, region or county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(all_df, popdf, query_type, query_state=None, query_region=None, query_county=None, output=None, \n",
    "                output_directory=None):\n",
    "    assert query_type in ['State', 'County', 'Region']\n",
    "    assert output in ['inline', 'png']\n",
    "\n",
    "    df, label = select_locality(all_df, popdf, query_type, query_state, query_region, query_county)\n",
    "    df = df.sort_values(by='Last_Update', ignore_index=True)\n",
    "    if output == 'png':\n",
    "        output = label.replace(' ','_') + '.png'\n",
    "        output = output.replace(',','')\n",
    "        if output_directory==None:\n",
    "            output_directory='png'\n",
    "        output = f\"{output_directory}/{output}\"\n",
    "    else:\n",
    "        output = None\n",
    "    \n",
    "    new_cases(df) # add a new_cases column to the dataframe\n",
    "\n",
    "    new_case_plot(df, label, days=14, centered=False, output=output)    \n",
    "    plt.close()\n",
    "    yellow_target(df, label, output=output)\n",
    "    plt.close()\n",
    "    trending(df, label, output=output)\n",
    "    plt.close()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate state graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Florida:Washington          : 100%|██████████| 67/67 [01:39<00:00,  1.49s/it]\n",
      "0it [00:00, ?it/s]\n",
      "New Jersey:Warren              : 100%|██████████| 21/21 [00:29<00:00,  1.40s/it]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All states completed.\n"
     ]
    }
   ],
   "source": [
    "#states = ['Pennsylvania', 'Georgia', 'New York', 'Florida', 'New Jersey']\n",
    "states = ['Florida', 'New Jersey']\n",
    "for state in states:\n",
    "    outdir = f'states/{state}'.replace(' ','_')\n",
    "    counties = set(popdf[popdf.State==state].County)\n",
    "\n",
    "    if state == 'New York': # remove NYC counties; JHU conflates into a single county\n",
    "        counties -= set(['Bronx', 'New York', 'Kings', 'Queens', 'Richmond', 'New York City'])\n",
    "\n",
    "    pbar = tqdm(sorted(counties))\n",
    "    for county in pbar:\n",
    "        pbar.set_description(f\"{state}:{county:20}\")\n",
    "        run_pipeline(all_df, popdf, query_type=\"County\", query_state=state, query_county=county, output=\"png\",\n",
    "                    output_directory=outdir)\n",
    "\n",
    "    regions = set(popdf.Region[(popdf.Region.notnull()) & (popdf.State==state)])\n",
    "    pbar = tqdm(sorted(regions))\n",
    "    for region in pbar:\n",
    "        pbar.set_description(f\"{state}:{region:20}\")\n",
    "        run_pipeline(all_df, popdf, query_type=\"Region\", query_state=state, query_region=region, output=\"png\",\n",
    "                     output_directory=outdir)\n",
    "        \n",
    "    run_pipeline(all_df, popdf, query_type=\"State\", query_state=state, output='png',\n",
    "                 output_directory=outdir)\n",
    "\n",
    "print(f\"All states completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-off graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup variables for this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_off=False\n",
    "if one_off:\n",
    "    query_type='Region'\n",
    "    query_state='New York'\n",
    "    query_region='New York City'\n",
    "    query_county=None\n",
    "    output='png'\n",
    "    output_dir='png'\n",
    "    df = run_pipeline(all_df, popdf, query_type=\"Region\", query_state=query_state, query_county=query_county, \n",
    "                      query_region=query_region, output=\"png\", output_directory=outdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
